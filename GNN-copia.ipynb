{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54b0e4ad",
   "metadata": {},
   "source": [
    "# --------------------------Segunda parte-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e0434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "\n",
    "# Load data from .h5 files\n",
    "train_df = pd.read_hdf('train_df.h5', 'df')\n",
    "val_df = pd.read_hdf('val_df.h5', 'df')\n",
    "test_df = pd.read_hdf('test_df.h5', 'df')\n",
    "\n",
    "epochs = 8\n",
    "batch_size = 16\n",
    "SMALL_DATA = False\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "if SMALL_DATA:\n",
    "    train_df = train_df[:128]\n",
    "    val_df = test_df[:128]\n",
    "    test_df = test_df[:128]\n",
    "\n",
    "col_names = list(train_df.columns.values)\n",
    "ing_names = col_names[:-3]\n",
    "targets = ing_names\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.df.iloc[idx]['path']\n",
    "        try:\n",
    "            image = cv2.imread(image_path, 1)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Failed to read image at {image_path}\")\n",
    "            if image.shape[0] == 0 or image.shape[1] == 0:\n",
    "                raise ValueError(f\"Invalid image size for {image_path}\")\n",
    "\n",
    "            x = cv2.resize(image, IMG_SIZE)\n",
    "            x = torch.from_numpy(x.transpose(2, 0, 1)).float()\n",
    "\n",
    "            sl_class_id = int(self.df.iloc[idx]['sl_class_id'])\n",
    "            sl_onehot = np.array(sl_class_id)\n",
    "            sl_onehot = (np.arange(len(classes)) == sl_onehot).astype(np.float32)\n",
    "            sl_y = torch.from_numpy(sl_onehot)\n",
    "\n",
    "            ml_y = []\n",
    "            for i in range(len(base_ing)):\n",
    "                ml_y.append(self.df.iloc[idx][str(i)])\n",
    "            ml_y = np.array(ml_y, dtype=np.float32)\n",
    "\n",
    "            return (x, sl_y, ml_y)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading image at {image_path}: {str(e)}\")\n",
    "            # Devuelve un valor predeterminado o imagen vacÃ­a\n",
    "            x = torch.zeros((3, IMG_SIZE[0], IMG_SIZE[1])).float()\n",
    "            sl_y = torch.zeros(len(classes)).float()\n",
    "            ml_y = np.zeros(len(base_ing), dtype=np.float32)\n",
    "            return (x, sl_y, ml_y)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Create DataLoader objects for training, validation, and testing sets\n",
    "train_dataset = CustomDataset(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = CustomDataset(val_df)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = CustomDataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# ResNet50 Model\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "# Disable grad for all conv layers\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add two heads\n",
    "resnet.last_linear = resnet.fc\n",
    "n_features = resnet.fc.out_features\n",
    "head_sl = nn.Sequential(\n",
    "    nn.Linear(n_features, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(512, len(classes))\n",
    ")\n",
    "head_ml = nn.Sequential(\n",
    "    nn.Linear(n_features, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(512, len(base_ing)),\n",
    "    nn.Sigmoid()\n",
    ")  \n",
    "\n",
    "# Connect two heads\n",
    "class FoodModel(nn.Module):\n",
    "    def __init__(self, base_model, head_sl, head_ml):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.head_sl = head_sl\n",
    "        self.head_ml = head_ml\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        sl = self.head_sl(x)\n",
    "        ml = self.head_ml(x)\n",
    "        return sl, ml\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FoodModel(resnet, head_sl, head_ml)\n",
    "model.to(device)\n",
    "\n",
    "# Define Loss\n",
    "sl_loss_fn = nn.CrossEntropyLoss()\n",
    "ml_loss_fn = nn.BCELoss()\n",
    "\n",
    "# Define Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "def train_step(model, optimizer, sl_loss_fn, ml_loss_fn, data, device):\n",
    "    # Retrieve data\n",
    "    x, sl_y, ml_y = data\n",
    "\n",
    "    # Convert to device\n",
    "    x = x.to(device)\n",
    "    sl_y = sl_y.to(device)\n",
    "    ml_y = ml_y.to(device)\n",
    "\n",
    "    # Zero out gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    sl_preds, ml_preds = model(x)\n",
    "\n",
    "    # Calculate losses\n",
    "    sl_loss = sl_loss_fn(sl_preds, torch.argmax(sl_y, dim=1))\n",
    "    ml_loss = ml_loss_fn(ml_preds, ml_y)\n",
    "    loss = sl_loss + ml_loss\n",
    "\n",
    "    # Calculate F1 score\n",
    "    sl_f1 = f1_score(torch.argmax(sl_y, dim=1).cpu().numpy(), torch.argmax(sl_preds, dim=1).cpu().numpy(), average='macro')\n",
    "    ml_f1 = f1_score(ml_y.cpu().numpy(), (ml_preds > 0.5).cpu().numpy(), average='macro')\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Step optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # Return losses and F1 scores\n",
    "    return sl_loss.item(), ml_loss.item(), sl_f1, ml_f1\n",
    "\n",
    "# Lists to store loss and accuracy for plotting\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "epochs = 300\n",
    "for i in tqdm(range(epochs), desc='Epochs'):\n",
    "    print(\"Epoch \", i)\n",
    "    total_sl_loss = 0.0\n",
    "    total_ml_loss = 0.0\n",
    "    total_sl_f1 = 0.0\n",
    "    total_ml_f1 = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with tqdm(train_loader, desc='Training', total=len(train_loader), miniters=1) as pbar:\n",
    "        for data in pbar: \n",
    "            SL_loss, ML_loss, SL_f1, ML_f1 = train_step(model, optimizer, sl_loss_fn, ml_loss_fn, data, device)\n",
    "\n",
    "            total_sl_loss += SL_loss\n",
    "            total_ml_loss += ML_loss\n",
    "            total_sl_f1 += SL_f1\n",
    "            total_ml_f1 += ML_f1\n",
    "            total_samples += data[0].size(0)\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'SL Loss': total_sl_loss / total_samples,\n",
    "                'ML Loss': total_ml_loss / total_samples,\n",
    "                'SL F1': total_sl_f1 / total_samples,\n",
    "                'ML F1': total_ml_f1 / total_samples\n",
    "            })\n",
    "\n",
    "    # Calculate average losses and accuracy\n",
    "    avg_sl_loss = total_sl_loss / len(train_loader)\n",
    "    avg_ml_loss = total_ml_loss / len(train_loader)\n",
    "    avg_sl_f1 = total_sl_f1 / len(train_loader)\n",
    "    avg_ml_f1 = total_ml_f1 / len(train_loader)\n",
    "\n",
    "    # Append losses and accuracy to the lists\n",
    "    train_losses.append(avg_sl_loss + avg_ml_loss)\n",
    "    train_accs.append(avg_sl_f1)\n",
    "\n",
    "# Plot loss and accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(train_accs, label='Train Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.title('Training Loss and Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Load a test image\n",
    "img_path = '82439.jpg'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "plt.imshow(img)\n",
    "\n",
    "# Resize image and convert to tensor\n",
    "transform = transforms.Compose([transforms.Resize(IMG_SIZE), transforms.ToTensor()])\n",
    "img = transform(img)\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "# Get model predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sl_preds, ml_preds = model(img.to(device))\n",
    "\n",
    "sl_preds = torch.nn.functional.softmax(sl_preds)\n",
    "sl_preds = sl_preds.cpu().numpy()\n",
    "ml_preds = ml_preds.cpu().numpy()\n",
    "\n",
    "# Plot prediction results\n",
    "sl_preds = sl_preds.squeeze()\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(classes, sl_preds)\n",
    "plt.title('Softmax Prediction')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Food Category')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()\n",
    "\n",
    "ml_preds = ml_preds.squeeze()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(base_ing, ml_preds)\n",
    "plt.title('Sigmoid Prediction')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Ingredient')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf65d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "\n",
    "# Load data from .h5 files\n",
    "train_df = pd.read_hdf('train_df.h5', 'df')\n",
    "val_df = pd.read_hdf('val_df.h5', 'df')\n",
    "test_df = pd.read_hdf('test_df.h5', 'df')\n",
    "\n",
    "epochs = 8\n",
    "batch_size = 16\n",
    "SMALL_DATA = False\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "if SMALL_DATA:\n",
    "    train_df = train_df[:128]\n",
    "    val_df = test_df[:128]\n",
    "    test_df = test_df[:128]\n",
    "\n",
    "col_names = list(train_df.columns.values)\n",
    "ing_names = col_names[:-3]\n",
    "targets = ing_names\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.df.iloc[idx]['path']\n",
    "        try:\n",
    "            image = cv2.imread(image_path, 1)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Failed to read image at {image_path}\")\n",
    "            if image.shape[0] == 0 or image.shape[1] == 0:\n",
    "                raise ValueError(f\"Invalid image size for {image_path}\")\n",
    "\n",
    "            x = cv2.resize(image, IMG_SIZE)\n",
    "            x = torch.from_numpy(x.transpose(2, 0, 1)).float()\n",
    "\n",
    "            sl_class_id = int(self.df.iloc[idx]['sl_class_id'])\n",
    "            sl_onehot = np.array(sl_class_id)\n",
    "            sl_onehot = (np.arange(len(classes)) == sl_onehot).astype(np.float32)\n",
    "            sl_y = torch.from_numpy(sl_onehot)\n",
    "\n",
    "            ml_y = []\n",
    "            for i in range(len(base_ing)):\n",
    "                ml_y.append(self.df.iloc[idx][str(i)])\n",
    "            ml_y = np.array(ml_y, dtype=np.float32)\n",
    "\n",
    "            return (x, sl_y, ml_y)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading image at {image_path}: {str(e)}\")\n",
    "            # Devuelve un valor predeterminado o imagen vacÃ­a\n",
    "            x = torch.zeros((3, IMG_SIZE[0], IMG_SIZE[1])).float()\n",
    "            sl_y = torch.zeros(len(classes)).float()\n",
    "            ml_y = np.zeros(len(base_ing), dtype=np.float32)\n",
    "            return (x, sl_y, ml_y)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Create DataLoader objects for training, validation, and testing sets\n",
    "train_dataset = CustomDataset(train_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = CustomDataset(val_df)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "test_dataset = CustomDataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# ResNet50 Model\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "# Disable grad for all conv layers\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add two heads\n",
    "resnet.last_linear = resnet.fc\n",
    "n_features = resnet.fc.out_features\n",
    "head_sl = nn.Sequential(\n",
    "    nn.Linear(n_features, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(512, len(classes))\n",
    ")\n",
    "head_ml = nn.Sequential(\n",
    "    nn.Linear(n_features, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(512, len(base_ing)),\n",
    "    nn.Sigmoid()\n",
    ")  \n",
    "\n",
    "# Connect two heads\n",
    "class FoodModel(nn.Module):\n",
    "    def __init__(self, base_model, head_sl, head_ml):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.head_sl = head_sl\n",
    "        self.head_ml = head_ml\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        sl = self.head_sl(x)\n",
    "        ml = self.head_ml(x)\n",
    "        return sl, ml\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FoodModel(resnet, head_sl, head_ml)\n",
    "model.to(device)\n",
    "\n",
    "# Define Loss\n",
    "sl_loss_fn = nn.CrossEntropyLoss()\n",
    "ml_loss_fn = nn.BCELoss()\n",
    "\n",
    "# Define Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "def train_step(model, optimizer, sl_loss_fn, ml_loss_fn, data, device):\n",
    "    # Retrieve data\n",
    "    x, sl_y, ml_y = data\n",
    "\n",
    "    # Convert to device\n",
    "    x = x.to(device)\n",
    "    sl_y = sl_y.to(device)\n",
    "    ml_y = ml_y.to(device)\n",
    "\n",
    "    # Zero out gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    sl_preds, ml_preds = model(x)\n",
    "\n",
    "    # Calculate losses\n",
    "    sl_loss = sl_loss_fn(sl_preds, torch.argmax(sl_y, dim=1))\n",
    "    ml_loss = ml_loss_fn(ml_preds, ml_y)\n",
    "    loss = sl_loss + ml_loss\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Step optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # Return losses\n",
    "    return sl_loss.item(), ml_loss.item()\n",
    "\n",
    "# Lists to store loss and accuracy for plotting\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "epochs = 300\n",
    "for i in tqdm(range(epochs), desc='Epochs'):\n",
    "    print(\"Epoch \", i)\n",
    "    total_sl_loss = 0.0\n",
    "    total_ml_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with tqdm(train_loader, desc='Training', total=len(train_loader), miniters=1) as pbar:\n",
    "        for data in pbar: \n",
    "            SL_loss, ML_loss = train_step(model, optimizer, sl_loss_fn, ml_loss_fn, data, device)\n",
    "\n",
    "            total_sl_loss += SL_loss\n",
    "            total_ml_loss += ML_loss\n",
    "            total_samples += data[0].size(0)\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'SL Loss': total_sl_loss / total_samples,\n",
    "                'ML Loss': total_ml_loss / total_samples\n",
    "            })\n",
    "\n",
    "    # Calculate average losses\n",
    "    avg_sl_loss = total_sl_loss / len(train_loader)\n",
    "    avg_ml_loss = total_ml_loss / len(train_loader)\n",
    "\n",
    "    # Append losses to the lists\n",
    "    train_losses.append(avg_sl_loss + avg_ml_loss)\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Load a test image\n",
    "img_path = '82439.jpg'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "plt.imshow(img)\n",
    "\n",
    "# Resize image and convert to tensor\n",
    "transform = transforms.Compose([transforms.Resize(IMG_SIZE), transforms.ToTensor()])\n",
    "img = transform(img)\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "# Get model predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sl_preds, ml_preds = model(img.to(device))\n",
    "\n",
    "sl_preds = torch.nn.functional.softmax(sl_preds)\n",
    "sl_preds = sl_preds.cpu().numpy()\n",
    "ml_preds = ml_preds.cpu().numpy()\n",
    "\n",
    "# Plot prediction results\n",
    "sl_preds = sl_preds.squeeze()\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(classes, sl_preds)\n",
    "plt.title('Softmax Prediction')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Food Category')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()\n",
    "\n",
    "ml_preds = ml_preds.squeeze()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(base_ing, ml_preds)\n",
    "plt.title('Sigmoid Prediction')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Ingredient')\n",
    "plt.ylabel('Probability')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
